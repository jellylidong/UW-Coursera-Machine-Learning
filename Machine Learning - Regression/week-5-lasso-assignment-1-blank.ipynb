{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up Graphlab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: /tmp/graphlab_server_1530851555.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to dlihit@ufl.edu and will expire on May 22, 2019.\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Linear regression:</pre>"
      ],
      "text/plain": [
       "Linear regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 21613</pre>"
      ],
      "text/plain": [
       "Number of examples          : 21613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of features          : 17</pre>"
      ],
      "text/plain": [
       "Number of features          : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 17</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 18</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Accelerated Gradient (FISTA)</pre>"
      ],
      "text/plain": [
       "Starting Accelerated Gradient (FISTA)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"
      ],
      "text/plain": [
       "Tuning step size. First iteration could take longer than subsequent iterations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.000002  | 0.339616     | 6962915.603493     | 426631.749026 |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.000002  | 0.339616     | 6962915.603493     | 426631.749026 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.000002  | 0.373610     | 6843144.200219     | 392488.929838 |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.000002  | 0.373610     | 6843144.200219     | 392488.929838 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.000002  | 0.412409     | 6831900.032123     | 385340.166783 |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.000002  | 0.412409     | 6831900.032123     | 385340.166783 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.000002  | 0.445699     | 6847166.848958     | 384842.383767 |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.000002  | 0.445699     | 6847166.848958     | 384842.383767 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 0.000002  | 0.485661     | 6869667.895833     | 385998.458623 |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 0.000002  | 0.485661     | 6869667.895833     | 385998.458623 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 0.000002  | 0.521680     | 6847177.773672     | 380824.455891 |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 0.000002  | 0.521680     | 6847177.773672     | 380824.455891 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+---------------+--------+\n",
      "|       name       | index |     value     | stderr |\n",
      "+------------------+-------+---------------+--------+\n",
      "|   (intercept)    |  None |  274873.05595 |  None  |\n",
      "|     bedrooms     |  None |      0.0      |  None  |\n",
      "| bedrooms_square  |  None |      0.0      |  None  |\n",
      "|    bathrooms     |  None | 8468.53108691 |  None  |\n",
      "|   sqft_living    |  None | 24.4207209824 |  None  |\n",
      "| sqft_living_sqrt |  None | 350.060553386 |  None  |\n",
      "|     sqft_lot     |  None |      0.0      |  None  |\n",
      "|  sqft_lot_sqrt   |  None |      0.0      |  None  |\n",
      "|      floors      |  None |      0.0      |  None  |\n",
      "|  floors_square   |  None |      0.0      |  None  |\n",
      "|    waterfront    |  None |      0.0      |  None  |\n",
      "|       view       |  None |      0.0      |  None  |\n",
      "|    condition     |  None |      0.0      |  None  |\n",
      "|      grade       |  None | 842.068034898 |  None  |\n",
      "|    sqft_above    |  None | 20.0247224171 |  None  |\n",
      "|  sqft_basement   |  None |      0.0      |  None  |\n",
      "|     yr_built     |  None |      0.0      |  None  |\n",
      "|   yr_renovated   |  None |      0.0      |  None  |\n",
      "+------------------+-------+---------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_all.coefficients.print_rows(18, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRSS(model, testData):\n",
    "    predictions = model.predict(testData)\n",
    "    rssVector = (predictions - testData['price'])**2\n",
    "    return sum(rssVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: 10.0, rss: 6.25766285142e+14\n",
      "l1: 31.6227766017, rss: 6.25766285362e+14\n",
      "l1: 100.0, rss: 6.25766286058e+14\n",
      "l1: 316.227766017, rss: 6.25766288257e+14\n",
      "l1: 1000.0, rss: 6.25766295212e+14\n",
      "l1: 3162.27766017, rss: 6.25766317206e+14\n",
      "l1: 10000.0, rss: 6.25766386761e+14\n",
      "l1: 31622.7766017, rss: 6.25766606749e+14\n",
      "l1: 100000.0, rss: 6.25767302792e+14\n",
      "l1: 316227.766017, rss: 6.25769507644e+14\n",
      "l1: 1000000.0, rss: 6.25776517727e+14\n",
      "l1: 3162277.66017, rss: 6.25799062845e+14\n",
      "l1: 10000000.0, rss: 6.25883719085e+14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for l1 in np.logspace(1, 7, num=13):\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1, verbose=False)\n",
    "    rss = getRSS(model, validation)\n",
    "    print \"l1: \" + str(l1) + \", rss: \" + str(rss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION. *** What was the best value for the `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1: 10.0, rss: 6.25766285142e+14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+------------------+--------+\n",
      "|       name       | index |      value       | stderr |\n",
      "+------------------+-------+------------------+--------+\n",
      "|   (intercept)    |  None |  18993.4272128   |  None  |\n",
      "|     bedrooms     |  None |  7936.96767903   |  None  |\n",
      "| bedrooms_square  |  None |  936.993368193   |  None  |\n",
      "|    bathrooms     |  None |  25409.5889341   |  None  |\n",
      "|   sqft_living    |  None |  39.1151363797   |  None  |\n",
      "| sqft_living_sqrt |  None |  1124.65021281   |  None  |\n",
      "|     sqft_lot     |  None | 0.00348361822299 |  None  |\n",
      "|  sqft_lot_sqrt   |  None |  148.258391011   |  None  |\n",
      "|      floors      |  None |   21204.335467   |  None  |\n",
      "|  floors_square   |  None |  12915.5243361   |  None  |\n",
      "|    waterfront    |  None |  601905.594545   |  None  |\n",
      "|       view       |  None |  93312.8573119   |  None  |\n",
      "|    condition     |  None |  6609.03571245   |  None  |\n",
      "|      grade       |  None |  6206.93999188   |  None  |\n",
      "|    sqft_above    |  None |  43.2870534193   |  None  |\n",
      "|  sqft_basement   |  None |  122.367827534   |  None  |\n",
      "|     yr_built     |  None |  9.43363539372   |  None  |\n",
      "|   yr_renovated   |  None |  56.0720034488   |  None  |\n",
      "+------------------+-------+------------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=10.0, verbose=False)\n",
    "model.coefficients.print_rows(18, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: 100000000.0, rss: 6.27492659875e+14, nnz: 18\n",
      "l1: 127427498.57, rss: 6.28210516771e+14, nnz: 18\n",
      "l1: 162377673.919, rss: 6.29176689541e+14, nnz: 18\n",
      "l1: 206913808.111, rss: 6.30650082719e+14, nnz: 18\n",
      "l1: 263665089.873, rss: 6.32940229287e+14, nnz: 17\n",
      "l1: 335981828.628, rss: 6.3626814023e+14, nnz: 17\n",
      "l1: 428133239.872, rss: 6.41261198311e+14, nnz: 17\n",
      "l1: 545559478.117, rss: 6.48983455376e+14, nnz: 17\n",
      "l1: 695192796.178, rss: 6.60962217696e+14, nnz: 17\n",
      "l1: 885866790.41, rss: 6.77261520728e+14, nnz: 16\n",
      "l1: 1128837891.68, rss: 7.01046815867e+14, nnz: 15\n",
      "l1: 1438449888.29, rss: 7.37850622829e+14, nnz: 15\n",
      "l1: 1832980710.83, rss: 7.9616310964e+14, nnz: 13\n",
      "l1: 2335721469.09, rss: 8.69018172894e+14, nnz: 12\n",
      "l1: 2976351441.63, rss: 9.66925692362e+14, nnz: 10\n",
      "l1: 3792690190.73, rss: 1.08186759232e+15, nnz: 6\n",
      "l1: 4832930238.57, rss: 1.24492736032e+15, nnz: 5\n",
      "l1: 6158482110.66, rss: 1.38416149024e+15, nnz: 3\n",
      "l1: 7847599703.51, rss: 1.23079472046e+15, nnz: 1\n",
      "l1: 10000000000.0, rss: 1.22915716064e+15, nnz: 1\n"
     ]
    }
   ],
   "source": [
    "for l1 in l1_penalty_values:\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1, verbose=False)\n",
    "    rss = getRSS(model, validation)\n",
    "    nnz = model['coefficients']['value'].nnz()\n",
    "    print \"l1: \" + str(l1) + \", rss: \" + str(rss) + \", nnz: \" + str(nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzeros` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzeros` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: 3414000000, rss: 1.04411288988e+15\n",
      "l1: 3415000000, rss: 1.0441929941e+15\n",
      "l1: 3416000000, rss: 1.04427310719e+15\n",
      "l1: 3417000000, rss: 1.04435322914e+15\n",
      "l1: 3418000000, rss: 1.04443335996e+15\n",
      "l1: 3419000000, rss: 1.04451352017e+15\n",
      "l1: 3420000000, rss: 1.04459366872e+15\n",
      "l1: 3421000000, rss: 1.04467382615e+15\n",
      "l1: 3422000000, rss: 1.04475401296e+15\n",
      "l1: 3423000000, rss: 1.04483418812e+15\n",
      "l1: 3424000000, rss: 1.04491437215e+15\n",
      "l1: 3425000000, rss: 1.04499456505e+15\n",
      "l1: 3426000000, rss: 1.04507476681e+15\n",
      "l1: 3427000000, rss: 1.04515499797e+15\n",
      "l1: 3428000000, rss: 1.04523521747e+15\n",
      "l1: 3429000000, rss: 1.04531544584e+15\n",
      "l1: 3430000000, rss: 1.04539570361e+15\n",
      "l1: 3431000000, rss: 1.04547594971e+15\n",
      "l1: 3432000000, rss: 1.04555620468e+15\n",
      "l1: 3433000000, rss: 1.04563646852e+15\n",
      "l1: 3434000000, rss: 1.04571674122e+15\n",
      "l1: 3435000000, rss: 1.04579704335e+15\n",
      "l1: 3436000000, rss: 1.04587733379e+15\n",
      "l1: 3437000000, rss: 1.04595763309e+15\n",
      "l1: 3438000000, rss: 1.04603796183e+15\n",
      "l1: 3439000000, rss: 1.04611827887e+15\n",
      "l1: 3440000000, rss: 1.04619860478e+15\n",
      "l1: 3441000000, rss: 1.04627893956e+15\n",
      "l1: 3442000000, rss: 1.04635928321e+15\n",
      "l1: 3443000000, rss: 1.04643965629e+15\n",
      "l1: 3444000000, rss: 1.04652001767e+15\n",
      "l1: 3445000000, rss: 1.04660038792e+15\n",
      "l1: 3446000000, rss: 1.04668148686e+15\n",
      "l1: 3447000000, rss: 1.04676770853e+15\n",
      "l1: 3448000000, rss: 1.04685394044e+15\n",
      "l1: 3449000000, rss: 1.04694018259e+15\n",
      "l1: 3450000000, rss: 1.04702643499e+15\n",
      "l1: 3451000000, rss: 1.04711271971e+15\n",
      "l1: 3452000000, rss: 1.0471989926e+15\n",
      "l1: 3453000000, rss: 1.04728527572e+15\n",
      "l1: 3454000000, rss: 1.04737159119e+15\n",
      "l1: 3455000000, rss: 1.0474578948e+15\n",
      "l1: 3456000000, rss: 1.04754420866e+15\n",
      "l1: 3457000000, rss: 1.04763053276e+15\n",
      "l1: 3458000000, rss: 1.0477168671e+15\n",
      "l1: 3459000000, rss: 1.04780323379e+15\n",
      "l1: 3460000000, rss: 1.04788958862e+15\n",
      "l1: 3461000000, rss: 1.0479759537e+15\n",
      "l1: 3462000000, rss: 1.04806235113e+15\n",
      "l1: 3463000000, rss: 1.04814873669e+15\n",
      "l1: 3464000000, rss: 1.04823513249e+15\n",
      "l1: 3465000000, rss: 1.04832153854e+15\n",
      "l1: 3466000000, rss: 1.04840779246e+15\n",
      "l1: 3467000000, rss: 1.04849400254e+15\n",
      "l1: 3468000000, rss: 1.04858020075e+15\n",
      "l1: 3469000000, rss: 1.04866640915e+15\n",
      "l1: 3470000000, rss: 1.04875264981e+15\n",
      "l1: 3471000000, rss: 1.0488388786e+15\n",
      "l1: 3472000000, rss: 1.04892511757e+15\n",
      "l1: 3473000000, rss: 1.04902327419e+15\n",
      "l1: 3474000000, rss: 1.0491353013e+15\n",
      "l1: 3475000000, rss: 1.04924737548e+15\n",
      "l1: 3476000000, rss: 1.04935943936e+15\n",
      "l1: 3477000000, rss: 1.04947152163e+15\n",
      "l1: 3478000000, rss: 1.04958365097e+15\n",
      "l1: 3479000000, rss: 1.04969577e+15\n",
      "l1: 3480000000, rss: 1.04980790742e+15\n",
      "l1: 3481000000, rss: 1.04992006321e+15\n",
      "l1: 3482000000, rss: 1.05003223739e+15\n",
      "l1: 3483000000, rss: 1.05014445867e+15\n",
      "l1: 3484000000, rss: 1.05025666961e+15\n",
      "l1: 3485000000, rss: 1.05036889894e+15\n",
      "l1: 3486000000, rss: 1.05048117539e+15\n",
      "l1: 3487000000, rss: 1.05059344148e+15\n",
      "l1: 3488000000, rss: 1.05070572596e+15\n",
      "l1: 3489000000, rss: 1.05081802881e+15\n",
      "l1: 3490000000, rss: 1.05093035005e+15\n",
      "l1: 3491000000, rss: 1.05104271844e+15\n",
      "l1: 3492000000, rss: 1.05115507644e+15\n",
      "l1: 3493000000, rss: 1.05126745283e+15\n",
      "l1: 3494000000, rss: 1.05137987638e+15\n",
      "l1: 3495000000, rss: 1.05149228954e+15\n",
      "l1: 3496000000, rss: 1.05160472108e+15\n",
      "l1: 3497000000, rss: 1.051717171e+15\n",
      "l1: 3498000000, rss: 1.0518296393e+15\n",
      "l1: 3499000000, rss: 1.05194215478e+15\n",
      "l1: 3500000000, rss: 1.05205465985e+15\n",
      "l1: 3501000000, rss: 1.0521671833e+15\n",
      "l1: 3502000000, rss: 1.05227975395e+15\n",
      "l1: 3503000000, rss: 1.05239231417e+15\n",
      "l1: 3504000000, rss: 1.05250489277e+15\n",
      "l1: 3505000000, rss: 1.05261748975e+15\n",
      "l1: 3506000000, rss: 1.05273010512e+15\n",
      "l1: 3507000000, rss: 1.0528427677e+15\n",
      "l1: 3508000000, rss: 1.05295541984e+15\n",
      "l1: 3509000000, rss: 1.05306809035e+15\n",
      "l1: 3510000000, rss: 1.0531808081e+15\n",
      "l1: 3511000000, rss: 1.05329351538e+15\n",
      "l1: 3512000000, rss: 1.05340624105e+15\n",
      "l1: 3513000000, rss: 1.05351898509e+15\n",
      "l1: 3514000000, rss: 1.05363174752e+15\n",
      "l1: 3515000000, rss: 1.0537445572e+15\n",
      "l1: 3516000000, rss: 1.0538573564e+15\n",
      "l1: 3517000000, rss: 1.05397017398e+15\n",
      "l1: 3518000000, rss: 1.05408303883e+15\n",
      "l1: 3519000000, rss: 1.05419589317e+15\n",
      "l1: 3520000000, rss: 1.0543087659e+15\n",
      "l1: 3521000000, rss: 1.05442165701e+15\n",
      "l1: 3522000000, rss: 1.0545345665e+15\n",
      "l1: 3523000000, rss: 1.05464752328e+15\n",
      "l1: 3524000000, rss: 1.05476046954e+15\n",
      "l1: 3525000000, rss: 1.05487343418e+15\n",
      "l1: 3526000000, rss: 1.05498644613e+15\n",
      "l1: 3527000000, rss: 1.05509944754e+15\n",
      "l1: 3528000000, rss: 1.05521246733e+15\n",
      "l1: 3529000000, rss: 1.0553255055e+15\n",
      "l1: 3530000000, rss: 1.05543856205e+15\n",
      "l1: 3531000000, rss: 1.05555166594e+15\n",
      "l1: 3532000000, rss: 1.05566475926e+15\n",
      "l1: 3533000000, rss: 1.05577787096e+15\n",
      "l1: 3534000000, rss: 1.05589103001e+15\n",
      "l1: 3535000000, rss: 1.05600417848e+15\n",
      "l1: 3536000000, rss: 1.05611734534e+15\n",
      "l1: 3537000000, rss: 1.05623053057e+15\n",
      "l1: 3538000000, rss: 1.05634373419e+15\n",
      "l1: 3539000000, rss: 1.05645698517e+15\n",
      "l1: 3540000000, rss: 1.05656857358e+15\n",
      "l1: 3541000000, rss: 1.05667998157e+15\n",
      "l1: 3542000000, rss: 1.05679143574e+15\n",
      "l1: 3543000000, rss: 1.05690287902e+15\n",
      "l1: 3544000000, rss: 1.05701433994e+15\n",
      "l1: 3545000000, rss: 1.05712581851e+15\n",
      "l1: 3546000000, rss: 1.05723731472e+15\n",
      "l1: 3547000000, rss: 1.05734885713e+15\n",
      "l1: 3548000000, rss: 1.05746038863e+15\n",
      "l1: 3549000000, rss: 1.05757193777e+15\n",
      "l1: 3550000000, rss: 1.05768353312e+15\n",
      "l1: 3551000000, rss: 1.05779511755e+15\n",
      "l1: 3552000000, rss: 1.05790671963e+15\n",
      "l1: 3553000000, rss: 1.05801833934e+15\n",
      "l1: 3554000000, rss: 1.0581299767e+15\n",
      "l1: 3555000000, rss: 1.05824166029e+15\n",
      "l1: 3556000000, rss: 1.05835333294e+15\n",
      "l1: 3557000000, rss: 1.05846502323e+15\n",
      "l1: 3558000000, rss: 1.05857675976e+15\n",
      "l1: 3559000000, rss: 1.05868848534e+15\n",
      "l1: 3560000000, rss: 1.05880022856e+15\n",
      "l1: 3561000000, rss: 1.05891198943e+15\n",
      "l1: 3562000000, rss: 1.05902376794e+15\n",
      "l1: 3563000000, rss: 1.05913559271e+15\n",
      "l1: 3564000000, rss: 1.05924740651e+15\n",
      "l1: 3565000000, rss: 1.05935923794e+15\n",
      "l1: 3566000000, rss: 1.05947111566e+15\n",
      "l1: 3567000000, rss: 1.05958298239e+15\n",
      "l1: 3568000000, rss: 1.05969486676e+15\n",
      "l1: 3569000000, rss: 1.05980676877e+15\n",
      "l1: 3570000000, rss: 1.05991868843e+15\n",
      "l1: 3571000000, rss: 1.06003065439e+15\n",
      "l1: 3572000000, rss: 1.06014260933e+15\n",
      "l1: 3573000000, rss: 1.06025458192e+15\n",
      "l1: 3574000000, rss: 1.06036660082e+15\n",
      "l1: 3575000000, rss: 1.0604786087e+15\n",
      "l1: 3576000000, rss: 1.06059063422e+15\n",
      "l1: 3577000000, rss: 1.06070267738e+15\n",
      "l1: 3578000000, rss: 1.06081473818e+15\n",
      "l1: 3579000000, rss: 1.06092684532e+15\n",
      "l1: 3580000000, rss: 1.06103894142e+15\n",
      "l1: 3581000000, rss: 1.06115105515e+15\n",
      "l1: 3582000000, rss: 1.06126321524e+15\n",
      "l1: 3583000000, rss: 1.06137536426e+15\n",
      "l1: 3584000000, rss: 1.06148753093e+15\n",
      "l1: 3585000000, rss: 1.06159971524e+15\n",
      "l1: 3586000000, rss: 1.06171191719e+15\n",
      "l1: 3587000000, rss: 1.06182416552e+15\n",
      "l1: 3588000000, rss: 1.06194353726e+15\n",
      "l1: 3589000000, rss: 1.06206476608e+15\n",
      "l1: 3590000000, rss: 1.06218604708e+15\n",
      "l1: 3591000000, rss: 1.06230731816e+15\n",
      "l1: 3592000000, rss: 1.06242861037e+15\n",
      "l1: 3593000000, rss: 1.0625499237e+15\n",
      "l1: 3594000000, rss: 1.06267125816e+15\n",
      "l1: 3595000000, rss: 1.06279264481e+15\n",
      "l1: 3596000000, rss: 1.06291402152e+15\n",
      "l1: 3597000000, rss: 1.06303541935e+15\n",
      "l1: 3598000000, rss: 1.0631568694e+15\n",
      "l1: 3599000000, rss: 1.06327830948e+15\n",
      "l1: 3600000000, rss: 1.0633997707e+15\n",
      "l1: 3601000000, rss: 1.06352125303e+15\n",
      "l1: 3602000000, rss: 1.06364275649e+15\n",
      "l1: 3603000000, rss: 1.06376431219e+15\n",
      "l1: 3604000000, rss: 1.06388585791e+15\n",
      "l1: 3605000000, rss: 1.06400742475e+15\n",
      "l1: 3606000000, rss: 1.06412904385e+15\n",
      "l1: 3607000000, rss: 1.06425065294e+15\n",
      "l1: 3608000000, rss: 1.06437228316e+15\n",
      "l1: 3609000000, rss: 1.0644939345e+15\n",
      "l1: 3610000000, rss: 1.06461560697e+15\n",
      "l1: 3611000000, rss: 1.06473733172e+15\n",
      "l1: 3612000000, rss: 1.06485904644e+15\n",
      "l1: 3613000000, rss: 1.06498078229e+15\n",
      "l1: 3614000000, rss: 1.06510257043e+15\n"
     ]
    }
   ],
   "source": [
    "nnz = 10\n",
    "l1 = 3399000000\n",
    "while nnz >= 7:\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1, verbose=False)\n",
    "    rss = getRSS(model, validation)\n",
    "    nnz = model['coefficients']['value'].nnz()\n",
    "    if(nnz == 7):\n",
    "        print \"l1: \" + str(l1) + \", rss: \" + str(rss)\n",
    "    if(nnz < 7):\n",
    "        break\n",
    "    l1 = l1 + 1000000\n",
    "\n",
    "l1_penalty_min = 0\n",
    "l1_penalty_max = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: 3414000000, rss: 1.04411288988e+15, nnz: 7\n",
      "+------------------+-------+---------------+--------+\n",
      "|       name       | index |     value     | stderr |\n",
      "+------------------+-------+---------------+--------+\n",
      "|   (intercept)    |  None | 220362.381399 |  None  |\n",
      "|     bedrooms     |  None | 786.731241997 |  None  |\n",
      "| bedrooms_square  |  None |      0.0      |  None  |\n",
      "|    bathrooms     |  None | 16049.4585874 |  None  |\n",
      "|   sqft_living    |  None | 32.5610497478 |  None  |\n",
      "| sqft_living_sqrt |  None | 698.522259956 |  None  |\n",
      "|     sqft_lot     |  None |      0.0      |  None  |\n",
      "|  sqft_lot_sqrt   |  None |      0.0      |  None  |\n",
      "|      floors      |  None |      0.0      |  None  |\n",
      "|  floors_square   |  None |      0.0      |  None  |\n",
      "|    waterfront    |  None |      0.0      |  None  |\n",
      "|       view       |  None |      0.0      |  None  |\n",
      "|    condition     |  None |      0.0      |  None  |\n",
      "|      grade       |  None |  2955.8268728 |  None  |\n",
      "|    sqft_above    |  None | 30.2381415569 |  None  |\n",
      "|  sqft_basement   |  None |      0.0      |  None  |\n",
      "|     yr_built     |  None |      0.0      |  None  |\n",
      "|   yr_renovated   |  None |      0.0      |  None  |\n",
      "+------------------+-------+---------------+--------+\n",
      "[18 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l1 = 3414000000\n",
    "model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=l1, verbose=False)\n",
    "rss = getRSS(model, validation)\n",
    "nnz = model['coefficients']['value'].nnz()\n",
    "print \"l1: \" + str(l1) + \", rss: \" + str(rss) + \", nnz: \" + str(nnz)\n",
    "model.coefficients.print_rows(18, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION.*** What values did you find for `l1_penalty_min` and `l1_penalty_max`, respectively? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
